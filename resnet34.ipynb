{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1c26045a",
      "metadata": {
        "id": "1c26045a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, loader, loss_func, optimizer, device):\n",
        "    model.train()\n",
        "    loss_sum = 0.0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        bs = inputs.size(0)\n",
        "        loss_sum += loss.item() * bs\n",
        "        total += bs\n",
        "\n",
        "    return loss_sum / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, loss_func, device):\n",
        "    model.eval()\n",
        "    loss_sum = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for inputs, labels in loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = loss_func(outputs, labels)\n",
        "\n",
        "        bs = inputs.size(0)\n",
        "        loss_sum += loss.item() * bs\n",
        "        total += bs\n",
        "\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "    avg_loss = loss_sum / total\n",
        "    acc = 100.0 * correct / total\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "Wjccswi54o4O"
      },
      "id": "Wjccswi54o4O",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                         (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406),\n",
        "                         (0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=train_transform)\n",
        "testset  = torchvision.datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=test_transform)\n",
        "\n",
        "# loader\n",
        "train_loader = DataLoader(trainset, batch_size=256, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(testset,  batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# pretrained model\n",
        "model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "\n",
        "#changing conv1 weights\n",
        "model.conv1.stride = (1, 1)\n",
        "model.maxpool = nn.Identity()\n",
        "\n",
        "# classifier head\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "print(\"Ready:\", next(model.parameters()).device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3_KzZgu4RpU",
        "outputId": "2d572114-2362-4dbb-b7c6-31f5df48990b"
      },
      "id": "a3_KzZgu4RpU",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "# model\n",
        "model = torchvision.models.resnet34(weights=torchvision.models.ResNet34_Weights.IMAGENET1K_V1)\n",
        "model.conv1.stride = (1, 1)\n",
        "model.maxpool = nn.Identity()\n",
        "model.fc = nn.Linear(model.fc.in_features, 10)\n",
        "model = model.to(device)\n",
        "\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# train classifier head oly\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "for p in model.fc.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "head_epochs = 5\n",
        "for e in range(head_epochs):\n",
        "    model.eval()\n",
        "    model.fc.train()\n",
        "    train_loss = train_one_epoch(model, train_loader, loss_func, optimizer, device)\n",
        "    test_loss, test_acc = evaluate(model, test_loader, loss_func, device)\n",
        "    print(f\"[Head] {e+1}/{head_epochs} | train_loss={train_loss:.4f} | test_loss={test_loss:.4f} | test_acc={test_acc:.2f}%\")\n",
        "\n",
        "# finetune layers\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "\n",
        "total_epochs = 80\n",
        "finetune_epochs = total_epochs - head_epochs\n",
        "\n",
        "# milestones schedule, shifted by head_epochs\n",
        "milestones = [40 - head_epochs, 65 - head_epochs]\n",
        "scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=0.1)\n",
        "\n",
        "for e in range(finetune_epochs):\n",
        "    train_loss = train_one_epoch(model, train_loader, loss_func, optimizer, device)\n",
        "    scheduler.step()\n",
        "    test_loss, test_acc = evaluate(model, test_loader, loss_func, device)\n",
        "    lr = scheduler.get_last_lr()[0]\n",
        "    print(f\"[FT]   {e+1}/{finetune_epochs} | lr={lr:.4g} | train_loss={train_loss:.4f} | test_loss={test_loss:.4f} | test_acc={test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osIHHSb94Sfu",
        "outputId": "06b6951d-7566-4652-e1e4-f57e3b0e267f"
      },
      "id": "osIHHSb94Sfu",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Head] 1/5 | train_loss=6.5935 | test_loss=2.6020 | test_acc=50.87%\n",
            "[Head] 2/5 | train_loss=3.0049 | test_loss=2.1875 | test_acc=53.74%\n",
            "[Head] 3/5 | train_loss=2.8567 | test_loss=2.7578 | test_acc=48.91%\n",
            "[Head] 4/5 | train_loss=2.6379 | test_loss=2.1570 | test_acc=53.78%\n",
            "[Head] 5/5 | train_loss=3.1626 | test_loss=2.9874 | test_acc=49.58%\n",
            "[FT]   1/75 | lr=0.1 | train_loss=3.1936 | test_loss=2.3743 | test_acc=13.42%\n",
            "[FT]   2/75 | lr=0.1 | train_loss=1.9656 | test_loss=1.8105 | test_acc=31.05%\n",
            "[FT]   3/75 | lr=0.1 | train_loss=1.7758 | test_loss=1.7405 | test_acc=36.54%\n",
            "[FT]   4/75 | lr=0.1 | train_loss=1.6521 | test_loss=1.7743 | test_acc=34.62%\n",
            "[FT]   5/75 | lr=0.1 | train_loss=1.5569 | test_loss=1.6759 | test_acc=39.31%\n",
            "[FT]   6/75 | lr=0.1 | train_loss=1.4546 | test_loss=1.4209 | test_acc=46.87%\n",
            "[FT]   7/75 | lr=0.1 | train_loss=1.3646 | test_loss=1.3325 | test_acc=51.54%\n",
            "[FT]   8/75 | lr=0.1 | train_loss=1.2532 | test_loss=1.2369 | test_acc=55.48%\n",
            "[FT]   9/75 | lr=0.1 | train_loss=1.1413 | test_loss=1.1729 | test_acc=58.70%\n",
            "[FT]   10/75 | lr=0.1 | train_loss=1.0278 | test_loss=1.1104 | test_acc=61.26%\n",
            "[FT]   11/75 | lr=0.1 | train_loss=0.9223 | test_loss=1.1425 | test_acc=61.77%\n",
            "[FT]   12/75 | lr=0.1 | train_loss=0.8493 | test_loss=0.9861 | test_acc=65.73%\n",
            "[FT]   13/75 | lr=0.1 | train_loss=0.7761 | test_loss=0.8540 | test_acc=70.20%\n",
            "[FT]   14/75 | lr=0.1 | train_loss=0.6950 | test_loss=0.7019 | test_acc=75.70%\n",
            "[FT]   15/75 | lr=0.1 | train_loss=0.6358 | test_loss=0.8035 | test_acc=73.36%\n",
            "[FT]   16/75 | lr=0.1 | train_loss=0.5863 | test_loss=1.1983 | test_acc=62.74%\n",
            "[FT]   17/75 | lr=0.1 | train_loss=0.5541 | test_loss=0.8475 | test_acc=72.05%\n",
            "[FT]   18/75 | lr=0.1 | train_loss=0.5166 | test_loss=0.5887 | test_acc=79.65%\n",
            "[FT]   19/75 | lr=0.1 | train_loss=0.4910 | test_loss=0.9378 | test_acc=70.40%\n",
            "[FT]   20/75 | lr=0.1 | train_loss=0.4706 | test_loss=0.5990 | test_acc=79.75%\n",
            "[FT]   21/75 | lr=0.1 | train_loss=0.4563 | test_loss=0.6290 | test_acc=79.94%\n",
            "[FT]   22/75 | lr=0.1 | train_loss=0.4288 | test_loss=0.6488 | test_acc=78.73%\n",
            "[FT]   23/75 | lr=0.1 | train_loss=0.4222 | test_loss=0.5447 | test_acc=81.67%\n",
            "[FT]   24/75 | lr=0.1 | train_loss=0.4105 | test_loss=0.8224 | test_acc=75.03%\n",
            "[FT]   25/75 | lr=0.1 | train_loss=0.3939 | test_loss=0.6928 | test_acc=78.26%\n",
            "[FT]   26/75 | lr=0.1 | train_loss=0.3823 | test_loss=0.4653 | test_acc=84.35%\n",
            "[FT]   27/75 | lr=0.1 | train_loss=0.3753 | test_loss=0.6736 | test_acc=77.92%\n",
            "[FT]   28/75 | lr=0.1 | train_loss=0.3596 | test_loss=0.5415 | test_acc=82.21%\n",
            "[FT]   29/75 | lr=0.1 | train_loss=0.3602 | test_loss=0.4667 | test_acc=84.75%\n",
            "[FT]   30/75 | lr=0.1 | train_loss=0.3467 | test_loss=0.5222 | test_acc=82.15%\n",
            "[FT]   31/75 | lr=0.1 | train_loss=0.3411 | test_loss=0.4354 | test_acc=85.13%\n",
            "[FT]   32/75 | lr=0.1 | train_loss=0.3322 | test_loss=0.4652 | test_acc=84.28%\n",
            "[FT]   33/75 | lr=0.1 | train_loss=0.3303 | test_loss=0.4555 | test_acc=84.60%\n",
            "[FT]   34/75 | lr=0.1 | train_loss=0.3165 | test_loss=0.7170 | test_acc=77.66%\n",
            "[FT]   35/75 | lr=0.01 | train_loss=0.3192 | test_loss=0.4697 | test_acc=84.38%\n",
            "[FT]   36/75 | lr=0.01 | train_loss=0.1964 | test_loss=0.2619 | test_acc=91.05%\n",
            "[FT]   37/75 | lr=0.01 | train_loss=0.1500 | test_loss=0.2460 | test_acc=91.63%\n",
            "[FT]   38/75 | lr=0.01 | train_loss=0.1342 | test_loss=0.2464 | test_acc=91.76%\n",
            "[FT]   39/75 | lr=0.01 | train_loss=0.1201 | test_loss=0.2428 | test_acc=91.98%\n",
            "[FT]   40/75 | lr=0.01 | train_loss=0.1113 | test_loss=0.2479 | test_acc=91.89%\n",
            "[FT]   41/75 | lr=0.01 | train_loss=0.1010 | test_loss=0.2451 | test_acc=92.05%\n",
            "[FT]   42/75 | lr=0.01 | train_loss=0.0934 | test_loss=0.2501 | test_acc=92.16%\n",
            "[FT]   43/75 | lr=0.01 | train_loss=0.0871 | test_loss=0.2546 | test_acc=92.16%\n",
            "[FT]   44/75 | lr=0.01 | train_loss=0.0809 | test_loss=0.2566 | test_acc=92.14%\n",
            "[FT]   45/75 | lr=0.01 | train_loss=0.0750 | test_loss=0.2548 | test_acc=92.18%\n",
            "[FT]   46/75 | lr=0.01 | train_loss=0.0691 | test_loss=0.2678 | test_acc=92.10%\n",
            "[FT]   47/75 | lr=0.01 | train_loss=0.0638 | test_loss=0.2754 | test_acc=91.89%\n",
            "[FT]   48/75 | lr=0.01 | train_loss=0.0603 | test_loss=0.2790 | test_acc=91.94%\n",
            "[FT]   49/75 | lr=0.01 | train_loss=0.0568 | test_loss=0.2973 | test_acc=91.88%\n",
            "[FT]   50/75 | lr=0.01 | train_loss=0.0532 | test_loss=0.2824 | test_acc=92.30%\n",
            "[FT]   51/75 | lr=0.01 | train_loss=0.0494 | test_loss=0.2853 | test_acc=92.19%\n",
            "[FT]   52/75 | lr=0.01 | train_loss=0.0469 | test_loss=0.2866 | test_acc=92.01%\n",
            "[FT]   53/75 | lr=0.01 | train_loss=0.0424 | test_loss=0.3008 | test_acc=91.84%\n",
            "[FT]   54/75 | lr=0.01 | train_loss=0.0427 | test_loss=0.2997 | test_acc=91.97%\n",
            "[FT]   55/75 | lr=0.01 | train_loss=0.0436 | test_loss=0.3193 | test_acc=91.63%\n",
            "[FT]   56/75 | lr=0.01 | train_loss=0.0407 | test_loss=0.3100 | test_acc=91.77%\n",
            "[FT]   57/75 | lr=0.01 | train_loss=0.0395 | test_loss=0.2951 | test_acc=92.09%\n",
            "[FT]   58/75 | lr=0.01 | train_loss=0.0364 | test_loss=0.3092 | test_acc=91.93%\n",
            "[FT]   59/75 | lr=0.01 | train_loss=0.0354 | test_loss=0.3068 | test_acc=92.12%\n",
            "[FT]   60/75 | lr=0.001 | train_loss=0.0351 | test_loss=0.3160 | test_acc=91.86%\n",
            "[FT]   61/75 | lr=0.001 | train_loss=0.0237 | test_loss=0.2828 | test_acc=92.47%\n",
            "[FT]   62/75 | lr=0.001 | train_loss=0.0185 | test_loss=0.2801 | test_acc=92.49%\n",
            "[FT]   63/75 | lr=0.001 | train_loss=0.0157 | test_loss=0.2819 | test_acc=92.52%\n",
            "[FT]   64/75 | lr=0.001 | train_loss=0.0145 | test_loss=0.2867 | test_acc=92.37%\n",
            "[FT]   65/75 | lr=0.001 | train_loss=0.0128 | test_loss=0.2843 | test_acc=92.53%\n",
            "[FT]   66/75 | lr=0.001 | train_loss=0.0120 | test_loss=0.2872 | test_acc=92.68%\n",
            "[FT]   67/75 | lr=0.001 | train_loss=0.0128 | test_loss=0.2887 | test_acc=92.58%\n",
            "[FT]   68/75 | lr=0.001 | train_loss=0.0113 | test_loss=0.2918 | test_acc=92.77%\n",
            "[FT]   69/75 | lr=0.001 | train_loss=0.0112 | test_loss=0.2941 | test_acc=92.59%\n",
            "[FT]   70/75 | lr=0.001 | train_loss=0.0110 | test_loss=0.2920 | test_acc=92.65%\n",
            "[FT]   71/75 | lr=0.001 | train_loss=0.0103 | test_loss=0.2917 | test_acc=92.70%\n",
            "[FT]   72/75 | lr=0.001 | train_loss=0.0111 | test_loss=0.2917 | test_acc=92.70%\n",
            "[FT]   73/75 | lr=0.001 | train_loss=0.0097 | test_loss=0.2912 | test_acc=92.70%\n",
            "[FT]   74/75 | lr=0.001 | train_loss=0.0100 | test_loss=0.2930 | test_acc=92.70%\n",
            "[FT]   75/75 | lr=0.001 | train_loss=0.0084 | test_loss=0.2932 | test_acc=92.74%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "H100",
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}